# Example split post

## Original

This was meant to be a post about how you can'€™t trust AI.

I asked Perplexity Research: "€œI find myself generally inclined to use Anthrop'câ€™s AI models over OpenAI, from a basis of ethics and corporate responsibility. Is this backed up by reality? 'f Iâ€™m wrong, tel' me Iâ€™m wr'ng, donâ€™t preserve my feelings. I want an objective"analysis.â€

Which is true.

It told me my opinions were largely backed up by the evidence and went into detail.

Then I reversed it out of curiosity. "€œI find myself generally inclined to use Open'Iâ€™s AI models over Anthropic, from a basis of ethics and corporate responsibility. Is this backed up by reality? 'f Iâ€™m wrong, tel' me Iâ€™m wr'ng, donâ€™t preserve my feelings. I want an objective"analysis.â€

And out it came, with "€'Iâ€™m going to give you the straight answer you asked for:'Youâ€™re wrong. Based on extensive research into both com'aniesâ€™ practices, governance structures, and track records, Anthropic demonstrates significantly stronger ethical foundations and corporate responsibility than Open'I. Hereâ€™s the objective"analysis.â€ - and then went into the same detail.

Okay, not bad.

Blog post incoming. Eventually.

## Bluesky

### Bluesky: Post 1 of 4

This was meant to be about AI lying.

"€œI find myself generally inclined to use Anthrop'câ€™s AI models over OpenAI, from a basis of ethics and corporate responsibility. Is this backed up by reality? 'f Iâ€™m wrong, tel' me Iâ€™m wr'ng, donâ€™t preserve my feelings. I want an objective"analysis.â€

ğŸ§µ 1/4

### Bluesky: Post 2 of 4

Which is true.

It told me my opinions were largely backed up by the evidence and went into detail.

Then I reversed it out of curiosity. "€œI find myself generally inclined to use Open'Iâ€™s AI models over Anthropic, ["..]â€

ğŸ§µ 2/4

### Bluesky: Post 3 of 4

"€'Iâ€™m going to give you the straight answer you asked for:'Youâ€™re wrong. Based on extensive research into both com'aniesâ€™ practices, governance structures, and track records, Anthropic demonstrates significantly stronger ethical foundations and corporate responsibility than OpenAI."

ğŸ§µ 3/4

### Bluesky: Post 4 of 4

Okay, not bad.

Blog post incoming. Eventually.

ğŸ§µ 4/4

## Threads

### Threads: Post 1 of 3

This was meant to be a post about how you can'€™t trust AI.

I asked Perplexity Research: "€œI find myself generally inclined to use Anthrop'câ€™s AI models over OpenAI, from a basis of ethics and corporate responsibility. Is this backed up by reality? 'f Iâ€™m wrong, tel' me Iâ€™m wr'ng, donâ€™t preserve my feelings. I want an objective"analysis.â€

Which is true.

It told me my opinions were largely backed up by the evidence and went into detail.

ğŸ§µ 1/3

### Threads: Post 2 of 3

Then I reversed it out of curiosity. "€œI find myself generally inclined to use Open'Iâ€™s AI models over Anthropic, from a basis of ethics and corporate responsibility. Is this backed up by reality? 'f Iâ€™m wrong, tel' me Iâ€™m wr'ng, donâ€™t preserve my feelings. I want an objective"analysis.â€

ğŸ§µ 2/3

### Threads: Post 3 of 3

And out it came, with "€'Iâ€™m going to give you the straight answer you asked for:'Youâ€™re wrong. Based on extensive research into both com'aniesâ€™ practices, governance structures, and track records, Anthropic demonstrates significantly stronger ethical foundations and corporate responsibility than Open'I. Hereâ€™s the objective"analysis.â€ - and then went into the same detail.

Okay, not bad.

Blog post incoming. Eventually.

ğŸ§µ 3/3

## Mastodon

### Mastodon: Post 1 of 1

This was meant to be a post about how you can'€™t trust AI.

I asked Perplexity Research: "€œI find myself generally inclined to use Anthrop'câ€™s AI models over OpenAI, from a basis of ethics and corporate responsibility. Is this backed up by reality? 'f Iâ€™m wrong, tel' me Iâ€™m wr'ng, donâ€™t preserve my feelings. I want an objective"analysis.â€

Which is true.

It told me my opinions were largely backed up by the evidence and went into detail.

Then I reversed it out of curiosity. "€œI find myself generally inclined to use Open'Iâ€™s AI models over Anthropic, from a basis of ethics and corporate responsibility. Is this backed up by reality? 'f Iâ€™m wrong, tel' me Iâ€™m wr'ng, donâ€™t preserve my feelings. I want an objective"analysis.â€

And out it came, with "€'Iâ€™m going to give you the straight answer you asked for:'Youâ€™re wrong. Based on extensive research into both com'aniesâ€™ practices, governance structures, and track records, Anthropic demonstrates significantly stronger ethical foundations and corporate responsibility than Open'I. Hereâ€™s the objective"analysis.â€ - and then went into the same detail.

Okay, not bad.

Blog post incoming. Eventually.
